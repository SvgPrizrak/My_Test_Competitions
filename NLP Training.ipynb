{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07459d6b-eba0-4efd-8c73-ffa4ad023342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\savic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\savic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\savic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\savic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\savic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "nltk.download(['movie_reviews', 'punkt', 'punkt_tab', 'wordnet', 'stopwords'])\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "\n",
    "from nltk.corpus import stopwords, movie_reviews\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ac5fc5e-ceb3-4b91-9c1f-cac0c404ce4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews count: 2000\n"
     ]
    }
   ],
   "source": [
    "# get negative and positive reviews\n",
    "pr, nr = [], []\n",
    "\n",
    "for rate in ['pos', 'neg']:\n",
    "    for fileid in movie_reviews.fileids(rate):\n",
    "        words = movie_reviews.words(fileid)\n",
    "        if rate == 'pos':\n",
    "            pr.append(' '.join(words))\n",
    "        else:\n",
    "            nr.append(' '.join(words))\n",
    "            \n",
    "print(f'Positive reviews count: {len(pr)}')\n",
    "print(f'Negative reviews count: {len(nr)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ceeb1b0-b951-4ffa-8580-7d48b28a7f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>films adapted from comic books have had plenty...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>every now and then a movie comes along from a ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you ' ve got mail works alot better than it de...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\" jaws \" is a rare film that grabs your attent...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>moviemaking is a lot like being the general ma...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>if anything , \" stigmata \" should be taken as ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>john boorman ' s \" zardoz \" is a goofy cinemat...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>the kids in the hall are an acquired taste . i...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>there was a time when john carpenter was a gre...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>two party guys bob their heads to haddaway ' s...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review rate\n",
       "0     films adapted from comic books have had plenty...  pos\n",
       "1     every now and then a movie comes along from a ...  pos\n",
       "2     you ' ve got mail works alot better than it de...  pos\n",
       "3     \" jaws \" is a rare film that grabs your attent...  pos\n",
       "4     moviemaking is a lot like being the general ma...  pos\n",
       "...                                                 ...  ...\n",
       "1995  if anything , \" stigmata \" should be taken as ...  neg\n",
       "1996  john boorman ' s \" zardoz \" is a goofy cinemat...  neg\n",
       "1997  the kids in the hall are an acquired taste . i...  neg\n",
       "1998  there was a time when john carpenter was a gre...  neg\n",
       "1999  two party guys bob their heads to haddaway ' s...  neg\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get full dataframe\n",
    "pos_df = pd.DataFrame(data=pr, columns=['review'])\n",
    "pos_df['rate'] = 'pos'\n",
    "neg_df = pd.DataFrame(data=nr, columns=['review'])\n",
    "neg_df['rate'] = 'neg'\n",
    "full_df = pd.concat([pos_df, neg_df], ignore_index=True)\n",
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bf857a1-0b37-4ebc-9402-d42a97055b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing URL and HTML words from text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 2000/2000 [00:00<00:00, 37341.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:07<00:00, 252.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowercasing text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 2000/2000 [00:00<00:00, 15499.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing punctuation from text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:00<00:00, 9613.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing stopwords from text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:02<00:00, 864.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing the most common words from text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:07<00:00, 266.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:06<00:00, 325.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 2000/2000 [00:00<00:00, 63404.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# get full text preprocessing\n",
    "def full_text_preprocessing(reviews_series: pd.Series = full_df['review'], \n",
    "                            tokenizer : nltk = sent_tokenize,\n",
    "                            stopwords : nltk.corpus.stopwords.words = stopwords.words('english'),\n",
    "                            stemmer : nltk.stem = None, \n",
    "                            lemmatizer : nltk.stem = WordNetLemmatizer()):\n",
    "\n",
    "    \"\"\"\n",
    "    Function makes full text preprocessing like removing punctuation / stopwords, lowercasing, tokenizing, stemming / lemmatizing\n",
    "\n",
    "    Args:\n",
    "    * reviews_series - pd.Series of input text;\n",
    "    * tokenizer - nltk.tokenizer working on input text; \n",
    "    * stopwords - stopwords for deleting from input text;\n",
    "    * stemmer - stemmer for input text - works if lemmatizer is None;\n",
    "    * lemmatizer - lemmatizer for input text - works if stemmer is None;\n",
    "\n",
    "    Returns:\n",
    "    * Output preprocessed text - pd.Series\n",
    "    \"\"\"\n",
    "\n",
    "    # checking stemmer and lemmatizer\n",
    "    if stemmer is None and lemmatizer is None:\n",
    "        print('Check your stemmer and lemmatizer: both of them cannot be None')\n",
    "        return\n",
    "    elif stemmer is not None and lemmatizer is not None:\n",
    "        print('Check your stemmer and lemmatizer: both of them cannot be not None')\n",
    "        return\n",
    "        \n",
    "    # remove URL and HTML code\n",
    "    def remove_url_and_html_words(tokens_lst: list):\n",
    "\n",
    "        \"\"\"\n",
    "        Function deletes HTML and URL pattern from input tokens list\n",
    "    \n",
    "        Args:\n",
    "        * tokens_lst;\n",
    "    \n",
    "        Returns:\n",
    "        * Output tokens list without HTML and URL pattern - list\n",
    "        \"\"\"\n",
    "        \n",
    "        # define a regular expression pattern to match URLs\n",
    "        url_pattern = r\"(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?\"\n",
    "        \n",
    "        # define a regular expression pattern to match HTML tags\n",
    "        html_pattern = r\"<[^>]+>\"\n",
    "    \n",
    "        # replace URLs with an empty string\n",
    "        cleaned_lst = re.sub(url_pattern, \"\", tokens_lst)\n",
    "    \n",
    "        # replace HTML tags with an empty string\n",
    "        cleaned_lst = re.sub(html_pattern, \"\", tokens_lst)\n",
    "    \n",
    "        return cleaned_lst\n",
    "\n",
    "    print('Removing URL and HTML words from text...')\n",
    "    reviews_series = reviews_series.progress_apply(lambda x: remove_url_and_html_words(x))\n",
    "    \n",
    "    # tokenization\n",
    "    print('Tokenizing text...')\n",
    "    tokens = reviews_series.progress_apply(lambda x: word_tokenize(x))\n",
    "\n",
    "    # lowercasing\n",
    "    print('Lowercasing text...')\n",
    "    tokens = tokens.progress_apply(lambda x: list(map(str.lower, x)))\n",
    "\n",
    "    # remove punctuation\n",
    "    print('Removing punctuation from text...')\n",
    "    def remove_punctation(tokens_lst: list):\n",
    "\n",
    "        \"\"\"\n",
    "        Function deletes punctuation from input tokens list\n",
    "    \n",
    "        Args:\n",
    "        * tokens_lst;\n",
    "    \n",
    "        Returns:\n",
    "        * Output tokens list without punctuation - list\n",
    "        \"\"\"\n",
    "        \n",
    "        return [token for token in tokens_lst if token not in string.punctuation + '``']\n",
    "\n",
    "    tokens = tokens.progress_apply(lambda x: remove_punctation(x))\n",
    "\n",
    "    # remove stopwords\n",
    "    print('Removing stopwords from text...')\n",
    "    def remove_stopwords(tokens_lst: list):\n",
    "\n",
    "        \"\"\"\n",
    "        Function deletes stopwords from input tokens list\n",
    "    \n",
    "        Args:\n",
    "        * tokens_lst;\n",
    "    \n",
    "        Returns:\n",
    "        * Output tokens list without stopwords - list\n",
    "        \"\"\"\n",
    "        \n",
    "        return [token for token in tokens_lst if token not in stopwords]\n",
    "\n",
    "    tokens = tokens.progress_apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "    # remove the most common words (e.g., the top 10% of words by frequency)\n",
    "    def remove_frequency_words(tokens_lst):\n",
    "        return [token for token in tokens_lst if nltk.FreqDist(token)[token] < nltk.FreqDist(token).N() * 0.1]\n",
    "\n",
    "    print('Removing the most common words from text...')\n",
    "    tokens = tokens.progress_apply(lambda x: remove_frequency_words(x))\n",
    "\n",
    "    # stemming or lemmatizing\n",
    "    def stemming(tokens_lst: list):\n",
    "\n",
    "        \"\"\"\n",
    "        Function makes stemming from input tokens list\n",
    "    \n",
    "        Args:\n",
    "        * tokens_lst;\n",
    "    \n",
    "        Returns:\n",
    "        * Output tokens list after stemming - list\n",
    "        \"\"\"\n",
    "        \n",
    "        return [stemmer.stem(token) for token in tokens_lst]\n",
    "\n",
    "    def lemmatizing(tokens_lst: list):\n",
    "\n",
    "        \"\"\"\n",
    "        Function makes lemmatizing from input tokens list\n",
    "    \n",
    "        Args:\n",
    "        * tokens_lst;\n",
    "    \n",
    "        Returns:\n",
    "        * Output tokens list after lemmatizing - list\n",
    "        \"\"\"\n",
    "        \n",
    "        return [lemmatizer.lemmatize(token) for token in tokens_lst]\n",
    "\n",
    "    if stemmer is not None:\n",
    "        print('Stemming...')\n",
    "        tokens = tokens.progress_apply(lambda x: stemming(x))\n",
    "    else:\n",
    "        print('Lemmatizing...')\n",
    "        tokens = tokens.progress_apply(lambda x: lemmatizing(x))\n",
    "\n",
    "    print('Joining...')\n",
    "    tokens = tokens.progress_apply(lambda x: ' '.join(x))\n",
    "\n",
    "    return tokens\n",
    "\n",
    "tokens = full_text_preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e3c7cdc-661d-4497-85a9-e28889931854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 1) (2000,)\n"
     ]
    }
   ],
   "source": [
    "# dataframe after full text preprocessing and get X, y\n",
    "for_model_df = pd.DataFrame(tokens)\n",
    "for_model_df['rate'] = full_df['rate']\n",
    "X, y = for_model_df[['review']], for_model_df['rate']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffe7d569-70a4-43c3-ae8c-71a8b82d6b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf transformer\n",
    "tf_idf_transformer = TfidfVectorizer(stop_words='english', ngram_range=(1, 5), max_features=150000)\n",
    "\n",
    "# instance of StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "# get train and test parts of dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, stratify=y, random_state=42)\n",
    "                      \n",
    "X_train_text = tf_idf_transformer.fit_transform(X_train['review'])\n",
    "X_test_text = tf_idf_transformer.transform(X_test['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5138cfaa-26c6-4fab-858a-80e6968dc4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "LogisticRegression() Train accuracy score: 1.0\n",
      "LogisticRegression() Train classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       1.00      1.00      1.00       700\n",
      "         pos       1.00      1.00      1.00       700\n",
      "\n",
      "    accuracy                           1.00      1400\n",
      "   macro avg       1.00      1.00      1.00      1400\n",
      "weighted avg       1.00      1.00      1.00      1400\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "LogisticRegression() Test accuracy score: 0.8266666666666667\n",
      "LogisticRegression() Test classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.85      0.80      0.82       300\n",
      "         pos       0.81      0.85      0.83       300\n",
      "\n",
      "    accuracy                           0.83       600\n",
      "   macro avg       0.83      0.83      0.83       600\n",
      "weighted avg       0.83      0.83      0.83       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "logreg = LogisticRegression()\n",
    "logreg_param_grid = [{'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']},\n",
    "                     {'penalty':['none', 'elasticnet', 'l1', 'l2']},\n",
    "                     {'C':np.logspace(-5, 5, 11)},\n",
    "                     {'max_iter': [300, 500, 1000, 2000]}]\n",
    "\n",
    "\n",
    "logreg_grid_search = GridSearchCV(estimator = logreg,  \n",
    "                                  param_grid = logreg_param_grid,\n",
    "                                  scoring = 'accuracy',\n",
    "                                  cv = skf,\n",
    "                                  verbose=3,\n",
    "                                  n_jobs=-1)\n",
    "\n",
    "logreg_grid_search.fit(X_train_text, y_train)\n",
    "\n",
    "y_logreg_train_pred = logreg_grid_search.predict(X_train_text)\n",
    "y_logreg_test_pred = logreg_grid_search.predict(X_test_text)\n",
    "\n",
    "# evaluation of model\n",
    "print(f'{logreg} Train accuracy score: {accuracy_score(y_true = y_train, y_pred = y_logreg_train_pred)}')\n",
    "print(f'{logreg} Train classification report:\\n {classification_report(y_true = y_train, y_pred = y_logreg_train_pred)}')\n",
    "print('-' * 70)\n",
    "print(f'{logreg} Test accuracy score: {accuracy_score(y_true = y_test, y_pred = y_logreg_test_pred)}')\n",
    "print(f'{logreg} Test classification report:\\n {classification_report(y_true = y_test, y_pred = y_logreg_test_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1badc75e-95f6-479a-9b68-068b4fb1f88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "DecisionTreeClassifier() Train accuracy score: 1.0\n",
      "DecisionTreeClassifier() Train classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       1.00      1.00      1.00       700\n",
      "         pos       1.00      1.00      1.00       700\n",
      "\n",
      "    accuracy                           1.00      1400\n",
      "   macro avg       1.00      1.00      1.00      1400\n",
      "weighted avg       1.00      1.00      1.00      1400\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "DecisionTreeClassifier() Test accuracy score: 0.635\n",
      "DecisionTreeClassifier() Test classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.63      0.65      0.64       300\n",
      "         pos       0.64      0.62      0.63       300\n",
      "\n",
      "    accuracy                           0.64       600\n",
      "   macro avg       0.64      0.64      0.63       600\n",
      "weighted avg       0.64      0.64      0.63       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# decision tree classifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt_param_grid = [{'criterion': ['gini', 'entropy', 'log_loss']},\n",
    "                 {'splitter': ['best', 'random']},\n",
    "                 {'max_depth': np.linspace(3, 7, 5)},\n",
    "                 {'min_samples_split': np.linspace(2, 5, 4)}]\n",
    "\n",
    "\n",
    "dt_grid_search = GridSearchCV(estimator = dt,  \n",
    "                              param_grid = dt_param_grid,\n",
    "                              scoring = 'accuracy',\n",
    "                              cv = skf,\n",
    "                              verbose=3,\n",
    "                              n_jobs=-1)\n",
    "\n",
    "dt_grid_search.fit(X_train_text, y_train)\n",
    "\n",
    "y_dt_train_pred = dt_grid_search.predict(X_train_text)\n",
    "y_dt_test_pred = dt_grid_search.predict(X_test_text)\n",
    "\n",
    "# evaluation of model\n",
    "print(f'{dt} Train accuracy score: {accuracy_score(y_true = y_train, y_pred = y_dt_train_pred)}')\n",
    "print(f'{dt} Train classification report:\\n {classification_report(y_true = y_train, y_pred = y_dt_train_pred)}')\n",
    "print('-' * 70)\n",
    "print(f'{dt} Test accuracy score: {accuracy_score(y_true = y_test, y_pred = y_dt_test_pred)}')\n",
    "print(f'{dt} Test classification report:\\n {classification_report(y_true = y_test, y_pred = y_dt_test_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fa63fea-0152-429a-a9e2-274c064a1839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "RandomForestClassifier() Train accuracy score: 1.0\n",
      "RandomForestClassifier() Train classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       1.00      1.00      1.00       700\n",
      "         pos       1.00      1.00      1.00       700\n",
      "\n",
      "    accuracy                           1.00      1400\n",
      "   macro avg       1.00      1.00      1.00      1400\n",
      "weighted avg       1.00      1.00      1.00      1400\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RandomForestClassifier() Test accuracy score: 0.835\n",
      "RandomForestClassifier() Test classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.79      0.92      0.85       300\n",
      "         pos       0.90      0.75      0.82       300\n",
      "\n",
      "    accuracy                           0.83       600\n",
      "   macro avg       0.84      0.83      0.83       600\n",
      "weighted avg       0.84      0.83      0.83       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random forest classifier\n",
    "rf = RandomForestClassifier()\n",
    "rf_param_grid = [{'criterion': ['gini', 'entropy', 'log_loss']},\n",
    "                 {'max_depth': np.linspace(3, 10, 8)},\n",
    "                 {'min_samples_split': np.linspace(2, 6, 5)},\n",
    "                 {'n_estimators': [300, 500, 1000, 2000]}]\n",
    "\n",
    "\n",
    "rf_grid_search = GridSearchCV(estimator = rf,  \n",
    "                              param_grid = rf_param_grid,\n",
    "                              scoring = 'accuracy',\n",
    "                              cv = skf,\n",
    "                              verbose=3,\n",
    "                              n_jobs=-1)\n",
    "\n",
    "rf_grid_search.fit(X_train_text, y_train)\n",
    "\n",
    "y_rf_train_pred = rf_grid_search.predict(X_train_text)\n",
    "y_rf_test_pred = rf_grid_search.predict(X_test_text)\n",
    "\n",
    "# evaluation of model\n",
    "print(f'{rf} Train accuracy score: {accuracy_score(y_true = y_train, y_pred = y_rf_train_pred)}')\n",
    "print(f'{rf} Train classification report:\\n {classification_report(y_true = y_train, y_pred = y_rf_train_pred)}')\n",
    "print('-' * 70)\n",
    "print(f'{rf} Test accuracy score: {accuracy_score(y_true = y_test, y_pred = y_rf_test_pred)}')\n",
    "print(f'{rf} Test classification report:\\n {classification_report(y_true = y_test, y_pred = y_rf_test_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ea5d714-3dcb-4024-8e23-b4291e0ac753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 29 candidates, totalling 145 fits\n",
      "SVC() Train accuracy score: 1.0\n",
      "SVC() Train classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       1.00      1.00      1.00       700\n",
      "         pos       1.00      1.00      1.00       700\n",
      "\n",
      "    accuracy                           1.00      1400\n",
      "   macro avg       1.00      1.00      1.00      1400\n",
      "weighted avg       1.00      1.00      1.00      1400\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "SVC() Test accuracy score: 0.8166666666666667\n",
      "SVC() Test classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.84      0.78      0.81       300\n",
      "         pos       0.80      0.85      0.82       300\n",
      "\n",
      "    accuracy                           0.82       600\n",
      "   macro avg       0.82      0.82      0.82       600\n",
      "weighted avg       0.82      0.82      0.82       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVC\n",
    "svc = SVC()\n",
    "svc_param_grid = [{'kernel': ['linear', 'poly', 'rbf', 'sigmoid']},\n",
    "                  {'C': np.logspace(-5, 5, 11)},\n",
    "                  {'degree': np.linspace(3, 10, 8)},\n",
    "                  {'gamma': ['scale', 'auto']},\n",
    "                  {'max_iter': [300, 500, 1000, 2000]}]\n",
    "\n",
    "\n",
    "svc_grid_search = GridSearchCV(estimator = svc,  \n",
    "                               param_grid = svc_param_grid,\n",
    "                               scoring = 'accuracy',\n",
    "                               cv = skf,\n",
    "                               verbose=3,\n",
    "                               n_jobs=-1)\n",
    "\n",
    "svc_grid_search.fit(X_train_text, y_train)\n",
    "\n",
    "y_svc_train_pred = svc_grid_search.predict(X_train_text)\n",
    "y_svc_test_pred = svc_grid_search.predict(X_test_text)\n",
    "\n",
    "# evaluation of model\n",
    "print(f'{svc} Train accuracy score: {accuracy_score(y_true = y_train, y_pred = y_svc_train_pred)}')\n",
    "print(f'{svc} Train classification report:\\n {classification_report(y_true = y_train, y_pred = y_svc_train_pred)}')\n",
    "print('-' * 70)\n",
    "print(f'{svc} Test accuracy score: {accuracy_score(y_true = y_test, y_pred = y_svc_test_pred)}')\n",
    "print(f'{svc} Test classification report:\\n {classification_report(y_true = y_test, y_pred = y_svc_test_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05690912-60a7-4a21-b7f6-ff43e84dff1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 17 candidates, totalling 85 fits\n",
      "[CV 1/5] END ....................booster=gbtree;, score=0.771 total time=   8.1s\n",
      "[CV 2/5] END ....................booster=gbtree;, score=0.771 total time=   8.2s\n",
      "[CV 3/5] END ....................booster=gbtree;, score=0.832 total time=   8.2s\n",
      "[CV 4/5] END ....................booster=gbtree;, score=0.786 total time=   8.0s\n",
      "[CV 5/5] END ....................booster=gbtree;, score=0.764 total time=   8.1s\n",
      "[CV 1/5] END ..................booster=gblinear;, score=0.761 total time=   0.1s\n",
      "[CV 2/5] END ..................booster=gblinear;, score=0.739 total time=   0.1s\n",
      "[CV 3/5] END ..................booster=gblinear;, score=0.789 total time=   0.1s\n",
      "[CV 4/5] END ..................booster=gblinear;, score=0.736 total time=   0.1s\n",
      "[CV 5/5] END ..................booster=gblinear;, score=0.729 total time=   0.1s\n",
      "[CV 1/5] END .......................max_depth=3.0;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .......................max_depth=3.0;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .......................max_depth=3.0;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .......................max_depth=3.0;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .......................max_depth=3.0;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .......................max_depth=4.0;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .......................max_depth=4.0;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .......................max_depth=4.0;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .......................max_depth=4.0;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .......................max_depth=4.0;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .......................max_depth=5.0;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .......................max_depth=5.0;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .......................max_depth=5.0;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .......................max_depth=5.0;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .......................max_depth=5.0;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .......................max_depth=6.0;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .......................max_depth=6.0;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .......................max_depth=6.0;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .......................max_depth=6.0;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .......................max_depth=6.0;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .......................max_depth=7.0;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .......................max_depth=7.0;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .......................max_depth=7.0;, score=nan total time=   0.1s\n",
      "[CV 4/5] END .......................max_depth=7.0;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .......................max_depth=7.0;, score=nan total time=   0.1s\n",
      "[CV 1/5] END ......................max_leaves=3.0;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ......................max_leaves=3.0;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ......................max_leaves=3.0;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ......................max_leaves=3.0;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ......................max_leaves=3.0;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ......................max_leaves=4.0;, score=nan total time=   0.1s\n",
      "[CV 2/5] END ......................max_leaves=4.0;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ......................max_leaves=4.0;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ......................max_leaves=4.0;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ......................max_leaves=4.0;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ......................max_leaves=5.0;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ......................max_leaves=5.0;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ......................max_leaves=5.0;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ......................max_leaves=5.0;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ......................max_leaves=5.0;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ......................max_leaves=6.0;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ......................max_leaves=6.0;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ......................max_leaves=6.0;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ......................max_leaves=6.0;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ......................max_leaves=6.0;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...................n_estimators=30;, score=0.764 total time=   3.3s\n",
      "[CV 2/5] END ...................n_estimators=30;, score=0.754 total time=   3.3s\n",
      "[CV 3/5] END ...................n_estimators=30;, score=0.782 total time=   3.5s\n",
      "[CV 4/5] END ...................n_estimators=30;, score=0.764 total time=   3.4s\n",
      "[CV 5/5] END ...................n_estimators=30;, score=0.736 total time=   3.3s\n",
      "[CV 1/5] END ...................n_estimators=50;, score=0.761 total time=   5.0s\n",
      "[CV 2/5] END ...................n_estimators=50;, score=0.754 total time=   4.8s\n",
      "[CV 3/5] END ...................n_estimators=50;, score=0.804 total time=   5.0s\n",
      "[CV 4/5] END ...................n_estimators=50;, score=0.789 total time=   5.0s\n",
      "[CV 5/5] END ...................n_estimators=50;, score=0.743 total time=   4.8s\n",
      "[CV 1/5] END ...................n_estimators=70;, score=0.764 total time=   6.3s\n",
      "[CV 2/5] END ...................n_estimators=70;, score=0.782 total time=   6.3s\n",
      "[CV 3/5] END ...................n_estimators=70;, score=0.825 total time=   6.4s\n",
      "[CV 4/5] END ...................n_estimators=70;, score=0.786 total time=   6.4s\n",
      "[CV 5/5] END ...................n_estimators=70;, score=0.746 total time=   6.4s\n",
      "[CV 1/5] END ..................n_estimators=100;, score=0.771 total time=   8.0s\n",
      "[CV 2/5] END ..................n_estimators=100;, score=0.771 total time=   8.1s\n",
      "[CV 3/5] END ..................n_estimators=100;, score=0.832 total time=   8.3s\n",
      "[CV 4/5] END ..................n_estimators=100;, score=0.786 total time=   8.2s\n",
      "[CV 5/5] END ..................n_estimators=100;, score=0.764 total time=   8.1s\n",
      "[CV 1/5] END ......sampling_method=gradient_based;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ......sampling_method=gradient_based;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ......sampling_method=gradient_based;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ......sampling_method=gradient_based;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ......sampling_method=gradient_based;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...........sampling_method=uniform;, score=0.771 total time=   8.1s\n",
      "[CV 2/5] END ...........sampling_method=uniform;, score=0.771 total time=   8.2s\n",
      "[CV 3/5] END ...........sampling_method=uniform;, score=0.832 total time=   8.2s\n",
      "[CV 4/5] END ...........sampling_method=uniform;, score=0.786 total time=   8.1s\n",
      "[CV 5/5] END ...........sampling_method=uniform;, score=0.764 total time=   8.1s\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...) Train accuracy score: 1.0\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...) Train classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       700\n",
      "           1       1.00      1.00      1.00       700\n",
      "\n",
      "    accuracy                           1.00      1400\n",
      "   macro avg       1.00      1.00      1.00      1400\n",
      "weighted avg       1.00      1.00      1.00      1400\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...) Test accuracy score: 0.7716666666666666\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...) Test classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78       300\n",
      "           1       0.79      0.74      0.76       300\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.77      0.77      0.77       600\n",
      "weighted avg       0.77      0.77      0.77       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGBCLassifier\n",
    "xgb = XGBClassifier()\n",
    "xgb_param_grid = [{'booster': ['gbtree', 'gblinear']},\n",
    "                  {'max_depth': np.linspace(3, 7, 5)},\n",
    "                  {'max_leaves': np.linspace(3, 6, 4)},\n",
    "                  {'n_estimators': [30, 50, 70, 100]},\n",
    "                  {'sampling_method': ['gradient_based', 'uniform']}]\n",
    "\n",
    "\n",
    "xgb_grid_search = GridSearchCV(estimator = xgb,  \n",
    "                               param_grid = xgb_param_grid,\n",
    "                               scoring = 'accuracy',\n",
    "                               cv = skf,\n",
    "                               verbose=3,\n",
    "                               n_jobs=-1)\n",
    "\n",
    "xgb_grid_search.fit(X_train_text, y_train.map({'neg': 0, 'pos': 1}))\n",
    "\n",
    "y_xgb_train_pred = xgb_grid_search.predict(X_train_text)\n",
    "y_xgb_test_pred = xgb_grid_search.predict(X_test_text)\n",
    "\n",
    "# evaluation of model\n",
    "print(f\"XGB Train accuracy score: {accuracy_score(y_true = y_train.map({'neg': 0, 'pos': 1}), y_pred = y_xgb_train_pred)}\")\n",
    "print(f\"XGB Train classification report:\\n {classification_report(y_true = y_train.map({'neg': 0, 'pos': 1}), y_pred = y_xgb_train_pred)}\")\n",
    "print('-' * 70)\n",
    "print(f\"XGB Test accuracy score: {accuracy_score(y_true = y_test.map({'neg': 0, 'pos': 1}), y_pred = y_xgb_test_pred)}\")\n",
    "print(f\"XGB Test classification report:\\n {classification_report(y_true = y_test.map({'neg': 0, 'pos': 1}), y_pred = y_xgb_test_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d5fa9de8-0897-4ed1-afda-54499ac0c4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6735714\ttest: 0.6566667\tbest: 0.6566667 (0)\ttotal: 702ms\tremaining: 4m 39s\n",
      "1:\tlearn: 0.6950000\ttest: 0.6633333\tbest: 0.6633333 (1)\ttotal: 1.36s\tremaining: 4m 31s\n",
      "2:\tlearn: 0.6992857\ttest: 0.6700000\tbest: 0.6700000 (2)\ttotal: 2.02s\tremaining: 4m 27s\n",
      "3:\tlearn: 0.7114286\ttest: 0.6866667\tbest: 0.6866667 (3)\ttotal: 2.67s\tremaining: 4m 24s\n",
      "4:\tlearn: 0.7092857\ttest: 0.6766667\tbest: 0.6866667 (3)\ttotal: 3.33s\tremaining: 4m 22s\n",
      "5:\tlearn: 0.7192857\ttest: 0.6966667\tbest: 0.6966667 (5)\ttotal: 3.97s\tremaining: 4m 20s\n",
      "6:\tlearn: 0.7128571\ttest: 0.6850000\tbest: 0.6966667 (5)\ttotal: 4.63s\tremaining: 4m 19s\n",
      "7:\tlearn: 0.7221429\ttest: 0.6916667\tbest: 0.6966667 (5)\ttotal: 5.27s\tremaining: 4m 18s\n",
      "8:\tlearn: 0.7221429\ttest: 0.6966667\tbest: 0.6966667 (5)\ttotal: 5.93s\tremaining: 4m 17s\n",
      "9:\tlearn: 0.7135714\ttest: 0.6850000\tbest: 0.6966667 (5)\ttotal: 6.61s\tremaining: 4m 17s\n",
      "10:\tlearn: 0.7128571\ttest: 0.6833333\tbest: 0.6966667 (5)\ttotal: 7.25s\tremaining: 4m 16s\n",
      "11:\tlearn: 0.7235714\ttest: 0.6800000\tbest: 0.6966667 (5)\ttotal: 7.92s\tremaining: 4m 16s\n",
      "12:\tlearn: 0.7328571\ttest: 0.6950000\tbest: 0.6966667 (5)\ttotal: 8.58s\tremaining: 4m 15s\n",
      "13:\tlearn: 0.7392857\ttest: 0.6833333\tbest: 0.6966667 (5)\ttotal: 9.26s\tremaining: 4m 15s\n",
      "14:\tlearn: 0.7392857\ttest: 0.6800000\tbest: 0.6966667 (5)\ttotal: 9.99s\tremaining: 4m 16s\n",
      "15:\tlearn: 0.7407143\ttest: 0.6816667\tbest: 0.6966667 (5)\ttotal: 10.7s\tremaining: 4m 15s\n",
      "16:\tlearn: 0.7392857\ttest: 0.6850000\tbest: 0.6966667 (5)\ttotal: 11.3s\tremaining: 4m 14s\n",
      "17:\tlearn: 0.7542857\ttest: 0.6933333\tbest: 0.6966667 (5)\ttotal: 12s\tremaining: 4m 13s\n",
      "18:\tlearn: 0.7578571\ttest: 0.7000000\tbest: 0.7000000 (18)\ttotal: 12.6s\tremaining: 4m 13s\n",
      "19:\tlearn: 0.7550000\ttest: 0.6950000\tbest: 0.7000000 (18)\ttotal: 13.3s\tremaining: 4m 12s\n",
      "20:\tlearn: 0.7578571\ttest: 0.7000000\tbest: 0.7000000 (18)\ttotal: 14s\tremaining: 4m 12s\n",
      "21:\tlearn: 0.7585714\ttest: 0.6983333\tbest: 0.7000000 (18)\ttotal: 14.6s\tremaining: 4m 11s\n",
      "22:\tlearn: 0.7621429\ttest: 0.7016667\tbest: 0.7016667 (22)\ttotal: 15.3s\tremaining: 4m 10s\n",
      "23:\tlearn: 0.7678571\ttest: 0.7016667\tbest: 0.7016667 (22)\ttotal: 16s\tremaining: 4m 10s\n",
      "24:\tlearn: 0.7721429\ttest: 0.6983333\tbest: 0.7016667 (22)\ttotal: 16.7s\tremaining: 4m 9s\n",
      "25:\tlearn: 0.7750000\ttest: 0.7066667\tbest: 0.7066667 (25)\ttotal: 17.3s\tremaining: 4m 8s\n",
      "26:\tlearn: 0.7778571\ttest: 0.7083333\tbest: 0.7083333 (26)\ttotal: 18s\tremaining: 4m 8s\n",
      "27:\tlearn: 0.7828571\ttest: 0.7066667\tbest: 0.7083333 (26)\ttotal: 18.6s\tremaining: 4m 7s\n",
      "28:\tlearn: 0.7857143\ttest: 0.7183333\tbest: 0.7183333 (28)\ttotal: 19.3s\tremaining: 4m 7s\n",
      "29:\tlearn: 0.7885714\ttest: 0.7133333\tbest: 0.7183333 (28)\ttotal: 20s\tremaining: 4m 6s\n",
      "30:\tlearn: 0.7857143\ttest: 0.7083333\tbest: 0.7183333 (28)\ttotal: 20.7s\tremaining: 4m 5s\n",
      "31:\tlearn: 0.7914286\ttest: 0.7083333\tbest: 0.7183333 (28)\ttotal: 21.3s\tremaining: 4m 5s\n",
      "32:\tlearn: 0.8000000\ttest: 0.7200000\tbest: 0.7200000 (32)\ttotal: 22s\tremaining: 4m 4s\n",
      "33:\tlearn: 0.7985714\ttest: 0.7183333\tbest: 0.7200000 (32)\ttotal: 22.7s\tremaining: 4m 4s\n",
      "34:\tlearn: 0.8028571\ttest: 0.7183333\tbest: 0.7200000 (32)\ttotal: 23.4s\tremaining: 4m 3s\n",
      "35:\tlearn: 0.8085714\ttest: 0.7150000\tbest: 0.7200000 (32)\ttotal: 24s\tremaining: 4m 2s\n",
      "36:\tlearn: 0.8100000\ttest: 0.7150000\tbest: 0.7200000 (32)\ttotal: 24.7s\tremaining: 4m 2s\n",
      "37:\tlearn: 0.8114286\ttest: 0.7150000\tbest: 0.7200000 (32)\ttotal: 25.4s\tremaining: 4m 1s\n",
      "38:\tlearn: 0.8185714\ttest: 0.7166667\tbest: 0.7200000 (32)\ttotal: 26.1s\tremaining: 4m 1s\n",
      "39:\tlearn: 0.8135714\ttest: 0.7100000\tbest: 0.7200000 (32)\ttotal: 26.7s\tremaining: 4m\n",
      "40:\tlearn: 0.8114286\ttest: 0.7150000\tbest: 0.7200000 (32)\ttotal: 27.5s\tremaining: 4m\n",
      "41:\tlearn: 0.8135714\ttest: 0.7216667\tbest: 0.7216667 (41)\ttotal: 28.2s\tremaining: 3m 59s\n",
      "42:\tlearn: 0.8135714\ttest: 0.7183333\tbest: 0.7216667 (41)\ttotal: 28.9s\tremaining: 3m 59s\n",
      "43:\tlearn: 0.8178571\ttest: 0.7216667\tbest: 0.7216667 (41)\ttotal: 29.5s\tremaining: 3m 58s\n",
      "44:\tlearn: 0.8200000\ttest: 0.7200000\tbest: 0.7216667 (41)\ttotal: 30.2s\tremaining: 3m 58s\n",
      "45:\tlearn: 0.8242857\ttest: 0.7183333\tbest: 0.7216667 (41)\ttotal: 30.9s\tremaining: 3m 57s\n",
      "46:\tlearn: 0.8207143\ttest: 0.7133333\tbest: 0.7216667 (41)\ttotal: 31.5s\tremaining: 3m 56s\n",
      "47:\tlearn: 0.8235714\ttest: 0.7166667\tbest: 0.7216667 (41)\ttotal: 32.2s\tremaining: 3m 56s\n",
      "48:\tlearn: 0.8257143\ttest: 0.7183333\tbest: 0.7216667 (41)\ttotal: 32.9s\tremaining: 3m 55s\n",
      "49:\tlearn: 0.8257143\ttest: 0.7150000\tbest: 0.7216667 (41)\ttotal: 33.6s\tremaining: 3m 54s\n",
      "50:\tlearn: 0.8264286\ttest: 0.7183333\tbest: 0.7216667 (41)\ttotal: 34.2s\tremaining: 3m 54s\n",
      "51:\tlearn: 0.8271429\ttest: 0.7216667\tbest: 0.7216667 (41)\ttotal: 34.9s\tremaining: 3m 53s\n",
      "52:\tlearn: 0.8292857\ttest: 0.7216667\tbest: 0.7216667 (41)\ttotal: 35.6s\tremaining: 3m 53s\n",
      "53:\tlearn: 0.8292857\ttest: 0.7283333\tbest: 0.7283333 (53)\ttotal: 36.3s\tremaining: 3m 52s\n",
      "54:\tlearn: 0.8350000\ttest: 0.7316667\tbest: 0.7316667 (54)\ttotal: 37s\tremaining: 3m 51s\n",
      "55:\tlearn: 0.8371429\ttest: 0.7316667\tbest: 0.7316667 (54)\ttotal: 37.7s\tremaining: 3m 51s\n",
      "56:\tlearn: 0.8407143\ttest: 0.7350000\tbest: 0.7350000 (56)\ttotal: 38.4s\tremaining: 3m 50s\n",
      "57:\tlearn: 0.8421429\ttest: 0.7383333\tbest: 0.7383333 (57)\ttotal: 39s\tremaining: 3m 50s\n",
      "58:\tlearn: 0.8421429\ttest: 0.7316667\tbest: 0.7383333 (57)\ttotal: 39.7s\tremaining: 3m 49s\n",
      "59:\tlearn: 0.8407143\ttest: 0.7350000\tbest: 0.7383333 (57)\ttotal: 40.4s\tremaining: 3m 48s\n",
      "60:\tlearn: 0.8414286\ttest: 0.7366667\tbest: 0.7383333 (57)\ttotal: 41s\tremaining: 3m 48s\n",
      "61:\tlearn: 0.8400000\ttest: 0.7383333\tbest: 0.7383333 (57)\ttotal: 41.7s\tremaining: 3m 47s\n",
      "62:\tlearn: 0.8435714\ttest: 0.7350000\tbest: 0.7383333 (57)\ttotal: 42.4s\tremaining: 3m 46s\n",
      "63:\tlearn: 0.8464286\ttest: 0.7366667\tbest: 0.7383333 (57)\ttotal: 43.2s\tremaining: 3m 46s\n",
      "64:\tlearn: 0.8492857\ttest: 0.7383333\tbest: 0.7383333 (57)\ttotal: 43.8s\tremaining: 3m 45s\n",
      "65:\tlearn: 0.8500000\ttest: 0.7366667\tbest: 0.7383333 (57)\ttotal: 44.5s\tremaining: 3m 45s\n",
      "66:\tlearn: 0.8500000\ttest: 0.7366667\tbest: 0.7383333 (57)\ttotal: 45.2s\tremaining: 3m 44s\n",
      "67:\tlearn: 0.8485714\ttest: 0.7433333\tbest: 0.7433333 (67)\ttotal: 45.9s\tremaining: 3m 43s\n",
      "68:\tlearn: 0.8485714\ttest: 0.7416667\tbest: 0.7433333 (67)\ttotal: 46.6s\tremaining: 3m 43s\n",
      "69:\tlearn: 0.8500000\ttest: 0.7416667\tbest: 0.7433333 (67)\ttotal: 47.2s\tremaining: 3m 42s\n",
      "70:\tlearn: 0.8492857\ttest: 0.7416667\tbest: 0.7433333 (67)\ttotal: 47.9s\tremaining: 3m 42s\n",
      "71:\tlearn: 0.8507143\ttest: 0.7466667\tbest: 0.7466667 (71)\ttotal: 48.6s\tremaining: 3m 41s\n",
      "72:\tlearn: 0.8535714\ttest: 0.7450000\tbest: 0.7466667 (71)\ttotal: 49.3s\tremaining: 3m 40s\n",
      "73:\tlearn: 0.8564286\ttest: 0.7466667\tbest: 0.7466667 (71)\ttotal: 50s\tremaining: 3m 40s\n",
      "74:\tlearn: 0.8578571\ttest: 0.7516667\tbest: 0.7516667 (74)\ttotal: 50.7s\tremaining: 3m 39s\n",
      "75:\tlearn: 0.8607143\ttest: 0.7533333\tbest: 0.7533333 (75)\ttotal: 51.4s\tremaining: 3m 38s\n",
      "76:\tlearn: 0.8635714\ttest: 0.7516667\tbest: 0.7533333 (75)\ttotal: 52s\tremaining: 3m 38s\n",
      "77:\tlearn: 0.8678571\ttest: 0.7483333\tbest: 0.7533333 (75)\ttotal: 52.7s\tremaining: 3m 37s\n",
      "78:\tlearn: 0.8678571\ttest: 0.7516667\tbest: 0.7533333 (75)\ttotal: 53.4s\tremaining: 3m 37s\n",
      "79:\tlearn: 0.8678571\ttest: 0.7500000\tbest: 0.7533333 (75)\ttotal: 54.1s\tremaining: 3m 36s\n",
      "80:\tlearn: 0.8692857\ttest: 0.7483333\tbest: 0.7533333 (75)\ttotal: 54.8s\tremaining: 3m 35s\n",
      "81:\tlearn: 0.8707143\ttest: 0.7483333\tbest: 0.7533333 (75)\ttotal: 55.5s\tremaining: 3m 35s\n",
      "82:\tlearn: 0.8721429\ttest: 0.7483333\tbest: 0.7533333 (75)\ttotal: 56.2s\tremaining: 3m 34s\n",
      "83:\tlearn: 0.8714286\ttest: 0.7450000\tbest: 0.7533333 (75)\ttotal: 56.9s\tremaining: 3m 33s\n",
      "84:\tlearn: 0.8707143\ttest: 0.7500000\tbest: 0.7533333 (75)\ttotal: 57.6s\tremaining: 3m 33s\n",
      "85:\tlearn: 0.8721429\ttest: 0.7483333\tbest: 0.7533333 (75)\ttotal: 58.2s\tremaining: 3m 32s\n",
      "86:\tlearn: 0.8714286\ttest: 0.7500000\tbest: 0.7533333 (75)\ttotal: 58.9s\tremaining: 3m 31s\n",
      "87:\tlearn: 0.8735714\ttest: 0.7483333\tbest: 0.7533333 (75)\ttotal: 59.6s\tremaining: 3m 31s\n",
      "88:\tlearn: 0.8728571\ttest: 0.7550000\tbest: 0.7550000 (88)\ttotal: 1m\tremaining: 3m 30s\n",
      "89:\tlearn: 0.8735714\ttest: 0.7566667\tbest: 0.7566667 (89)\ttotal: 1m\tremaining: 3m 29s\n",
      "90:\tlearn: 0.8750000\ttest: 0.7550000\tbest: 0.7566667 (89)\ttotal: 1m 1s\tremaining: 3m 29s\n",
      "91:\tlearn: 0.8764286\ttest: 0.7566667\tbest: 0.7566667 (89)\ttotal: 1m 2s\tremaining: 3m 28s\n",
      "92:\tlearn: 0.8771429\ttest: 0.7533333\tbest: 0.7566667 (89)\ttotal: 1m 2s\tremaining: 3m 27s\n",
      "93:\tlearn: 0.8778571\ttest: 0.7550000\tbest: 0.7566667 (89)\ttotal: 1m 3s\tremaining: 3m 27s\n",
      "94:\tlearn: 0.8778571\ttest: 0.7550000\tbest: 0.7566667 (89)\ttotal: 1m 4s\tremaining: 3m 26s\n",
      "95:\tlearn: 0.8800000\ttest: 0.7600000\tbest: 0.7600000 (95)\ttotal: 1m 5s\tremaining: 3m 26s\n",
      "96:\tlearn: 0.8792857\ttest: 0.7566667\tbest: 0.7600000 (95)\ttotal: 1m 5s\tremaining: 3m 25s\n",
      "97:\tlearn: 0.8792857\ttest: 0.7583333\tbest: 0.7600000 (95)\ttotal: 1m 6s\tremaining: 3m 24s\n",
      "98:\tlearn: 0.8800000\ttest: 0.7633333\tbest: 0.7633333 (98)\ttotal: 1m 7s\tremaining: 3m 24s\n",
      "99:\tlearn: 0.8821429\ttest: 0.7583333\tbest: 0.7633333 (98)\ttotal: 1m 7s\tremaining: 3m 23s\n",
      "100:\tlearn: 0.8828571\ttest: 0.7633333\tbest: 0.7633333 (98)\ttotal: 1m 8s\tremaining: 3m 22s\n",
      "101:\tlearn: 0.8850000\ttest: 0.7650000\tbest: 0.7650000 (101)\ttotal: 1m 9s\tremaining: 3m 22s\n",
      "102:\tlearn: 0.8850000\ttest: 0.7600000\tbest: 0.7650000 (101)\ttotal: 1m 9s\tremaining: 3m 21s\n",
      "103:\tlearn: 0.8871429\ttest: 0.7583333\tbest: 0.7650000 (101)\ttotal: 1m 10s\tremaining: 3m 20s\n",
      "104:\tlearn: 0.8878571\ttest: 0.7600000\tbest: 0.7650000 (101)\ttotal: 1m 11s\tremaining: 3m 20s\n",
      "105:\tlearn: 0.8892857\ttest: 0.7566667\tbest: 0.7650000 (101)\ttotal: 1m 11s\tremaining: 3m 19s\n",
      "106:\tlearn: 0.8871429\ttest: 0.7600000\tbest: 0.7650000 (101)\ttotal: 1m 12s\tremaining: 3m 18s\n",
      "107:\tlearn: 0.8878571\ttest: 0.7583333\tbest: 0.7650000 (101)\ttotal: 1m 13s\tremaining: 3m 18s\n",
      "108:\tlearn: 0.8878571\ttest: 0.7616667\tbest: 0.7650000 (101)\ttotal: 1m 13s\tremaining: 3m 17s\n",
      "109:\tlearn: 0.8878571\ttest: 0.7650000\tbest: 0.7650000 (101)\ttotal: 1m 14s\tremaining: 3m 16s\n",
      "110:\tlearn: 0.8871429\ttest: 0.7633333\tbest: 0.7650000 (101)\ttotal: 1m 15s\tremaining: 3m 16s\n",
      "111:\tlearn: 0.8900000\ttest: 0.7633333\tbest: 0.7650000 (101)\ttotal: 1m 16s\tremaining: 3m 15s\n",
      "112:\tlearn: 0.8928571\ttest: 0.7650000\tbest: 0.7650000 (101)\ttotal: 1m 16s\tremaining: 3m 14s\n",
      "113:\tlearn: 0.8935714\ttest: 0.7650000\tbest: 0.7650000 (101)\ttotal: 1m 17s\tremaining: 3m 14s\n",
      "114:\tlearn: 0.8942857\ttest: 0.7616667\tbest: 0.7650000 (101)\ttotal: 1m 18s\tremaining: 3m 13s\n",
      "115:\tlearn: 0.8957143\ttest: 0.7633333\tbest: 0.7650000 (101)\ttotal: 1m 18s\tremaining: 3m 12s\n",
      "116:\tlearn: 0.8971429\ttest: 0.7616667\tbest: 0.7650000 (101)\ttotal: 1m 19s\tremaining: 3m 12s\n",
      "117:\tlearn: 0.8971429\ttest: 0.7616667\tbest: 0.7650000 (101)\ttotal: 1m 20s\tremaining: 3m 11s\n",
      "118:\tlearn: 0.9000000\ttest: 0.7666667\tbest: 0.7666667 (118)\ttotal: 1m 20s\tremaining: 3m 10s\n",
      "119:\tlearn: 0.9014286\ttest: 0.7700000\tbest: 0.7700000 (119)\ttotal: 1m 21s\tremaining: 3m 10s\n",
      "120:\tlearn: 0.9007143\ttest: 0.7733333\tbest: 0.7733333 (120)\ttotal: 1m 22s\tremaining: 3m 9s\n",
      "121:\tlearn: 0.9000000\ttest: 0.7750000\tbest: 0.7750000 (121)\ttotal: 1m 22s\tremaining: 3m 9s\n",
      "122:\tlearn: 0.9014286\ttest: 0.7716667\tbest: 0.7750000 (121)\ttotal: 1m 23s\tremaining: 3m 8s\n",
      "123:\tlearn: 0.9035714\ttest: 0.7733333\tbest: 0.7750000 (121)\ttotal: 1m 24s\tremaining: 3m 7s\n",
      "124:\tlearn: 0.9042857\ttest: 0.7750000\tbest: 0.7750000 (121)\ttotal: 1m 25s\tremaining: 3m 7s\n",
      "125:\tlearn: 0.9057143\ttest: 0.7733333\tbest: 0.7750000 (121)\ttotal: 1m 25s\tremaining: 3m 6s\n",
      "126:\tlearn: 0.9064286\ttest: 0.7733333\tbest: 0.7750000 (121)\ttotal: 1m 26s\tremaining: 3m 5s\n",
      "127:\tlearn: 0.9064286\ttest: 0.7750000\tbest: 0.7750000 (121)\ttotal: 1m 27s\tremaining: 3m 4s\n",
      "128:\tlearn: 0.9042857\ttest: 0.7700000\tbest: 0.7750000 (121)\ttotal: 1m 27s\tremaining: 3m 4s\n",
      "129:\tlearn: 0.9050000\ttest: 0.7750000\tbest: 0.7750000 (121)\ttotal: 1m 28s\tremaining: 3m 3s\n",
      "130:\tlearn: 0.9035714\ttest: 0.7783333\tbest: 0.7783333 (130)\ttotal: 1m 29s\tremaining: 3m 2s\n",
      "131:\tlearn: 0.9071429\ttest: 0.7766667\tbest: 0.7783333 (130)\ttotal: 1m 29s\tremaining: 3m 2s\n",
      "132:\tlearn: 0.9092857\ttest: 0.7750000\tbest: 0.7783333 (130)\ttotal: 1m 30s\tremaining: 3m 1s\n",
      "133:\tlearn: 0.9107143\ttest: 0.7783333\tbest: 0.7783333 (130)\ttotal: 1m 31s\tremaining: 3m\n",
      "134:\tlearn: 0.9121429\ttest: 0.7816667\tbest: 0.7816667 (134)\ttotal: 1m 31s\tremaining: 3m\n",
      "135:\tlearn: 0.9114286\ttest: 0.7816667\tbest: 0.7816667 (134)\ttotal: 1m 32s\tremaining: 2m 59s\n",
      "136:\tlearn: 0.9114286\ttest: 0.7800000\tbest: 0.7816667 (134)\ttotal: 1m 33s\tremaining: 2m 58s\n",
      "137:\tlearn: 0.9121429\ttest: 0.7816667\tbest: 0.7816667 (134)\ttotal: 1m 33s\tremaining: 2m 58s\n",
      "138:\tlearn: 0.9121429\ttest: 0.7833333\tbest: 0.7833333 (138)\ttotal: 1m 34s\tremaining: 2m 57s\n",
      "139:\tlearn: 0.9128571\ttest: 0.7850000\tbest: 0.7850000 (139)\ttotal: 1m 35s\tremaining: 2m 56s\n",
      "140:\tlearn: 0.9128571\ttest: 0.7850000\tbest: 0.7850000 (139)\ttotal: 1m 35s\tremaining: 2m 56s\n",
      "141:\tlearn: 0.9142857\ttest: 0.7866667\tbest: 0.7866667 (141)\ttotal: 1m 36s\tremaining: 2m 55s\n",
      "142:\tlearn: 0.9135714\ttest: 0.7866667\tbest: 0.7866667 (141)\ttotal: 1m 37s\tremaining: 2m 54s\n",
      "143:\tlearn: 0.9135714\ttest: 0.7850000\tbest: 0.7866667 (141)\ttotal: 1m 37s\tremaining: 2m 54s\n",
      "144:\tlearn: 0.9128571\ttest: 0.7883333\tbest: 0.7883333 (144)\ttotal: 1m 38s\tremaining: 2m 53s\n",
      "145:\tlearn: 0.9142857\ttest: 0.7900000\tbest: 0.7900000 (145)\ttotal: 1m 39s\tremaining: 2m 52s\n",
      "146:\tlearn: 0.9142857\ttest: 0.7900000\tbest: 0.7900000 (145)\ttotal: 1m 40s\tremaining: 2m 52s\n",
      "147:\tlearn: 0.9164286\ttest: 0.7900000\tbest: 0.7900000 (145)\ttotal: 1m 40s\tremaining: 2m 51s\n",
      "148:\tlearn: 0.9171429\ttest: 0.7883333\tbest: 0.7900000 (145)\ttotal: 1m 41s\tremaining: 2m 50s\n",
      "149:\tlearn: 0.9192857\ttest: 0.7916667\tbest: 0.7916667 (149)\ttotal: 1m 42s\tremaining: 2m 50s\n",
      "150:\tlearn: 0.9192857\ttest: 0.7933333\tbest: 0.7933333 (150)\ttotal: 1m 42s\tremaining: 2m 49s\n",
      "151:\tlearn: 0.9192857\ttest: 0.7916667\tbest: 0.7933333 (150)\ttotal: 1m 43s\tremaining: 2m 48s\n",
      "152:\tlearn: 0.9192857\ttest: 0.7933333\tbest: 0.7933333 (150)\ttotal: 1m 44s\tremaining: 2m 48s\n",
      "153:\tlearn: 0.9185714\ttest: 0.7966667\tbest: 0.7966667 (153)\ttotal: 1m 44s\tremaining: 2m 47s\n",
      "154:\tlearn: 0.9192857\ttest: 0.8000000\tbest: 0.8000000 (154)\ttotal: 1m 45s\tremaining: 2m 46s\n",
      "155:\tlearn: 0.9178571\ttest: 0.7933333\tbest: 0.8000000 (154)\ttotal: 1m 46s\tremaining: 2m 46s\n",
      "156:\tlearn: 0.9192857\ttest: 0.7916667\tbest: 0.8000000 (154)\ttotal: 1m 46s\tremaining: 2m 45s\n",
      "157:\tlearn: 0.9200000\ttest: 0.7916667\tbest: 0.8000000 (154)\ttotal: 1m 47s\tremaining: 2m 44s\n",
      "158:\tlearn: 0.9192857\ttest: 0.7900000\tbest: 0.8000000 (154)\ttotal: 1m 48s\tremaining: 2m 44s\n",
      "159:\tlearn: 0.9200000\ttest: 0.7916667\tbest: 0.8000000 (154)\ttotal: 1m 48s\tremaining: 2m 43s\n",
      "160:\tlearn: 0.9200000\ttest: 0.7916667\tbest: 0.8000000 (154)\ttotal: 1m 49s\tremaining: 2m 42s\n",
      "161:\tlearn: 0.9200000\ttest: 0.7900000\tbest: 0.8000000 (154)\ttotal: 1m 50s\tremaining: 2m 42s\n",
      "162:\tlearn: 0.9207143\ttest: 0.7933333\tbest: 0.8000000 (154)\ttotal: 1m 51s\tremaining: 2m 41s\n",
      "163:\tlearn: 0.9228571\ttest: 0.7950000\tbest: 0.8000000 (154)\ttotal: 1m 51s\tremaining: 2m 40s\n",
      "164:\tlearn: 0.9221429\ttest: 0.7966667\tbest: 0.8000000 (154)\ttotal: 1m 52s\tremaining: 2m 40s\n",
      "165:\tlearn: 0.9228571\ttest: 0.7966667\tbest: 0.8000000 (154)\ttotal: 1m 53s\tremaining: 2m 39s\n",
      "166:\tlearn: 0.9228571\ttest: 0.7983333\tbest: 0.8000000 (154)\ttotal: 1m 53s\tremaining: 2m 38s\n",
      "167:\tlearn: 0.9221429\ttest: 0.8033333\tbest: 0.8033333 (167)\ttotal: 1m 54s\tremaining: 2m 38s\n",
      "168:\tlearn: 0.9228571\ttest: 0.8050000\tbest: 0.8050000 (168)\ttotal: 1m 55s\tremaining: 2m 37s\n",
      "169:\tlearn: 0.9250000\ttest: 0.8016667\tbest: 0.8050000 (168)\ttotal: 1m 55s\tremaining: 2m 36s\n",
      "170:\tlearn: 0.9257143\ttest: 0.8066667\tbest: 0.8066667 (170)\ttotal: 1m 56s\tremaining: 2m 36s\n",
      "171:\tlearn: 0.9300000\ttest: 0.8016667\tbest: 0.8066667 (170)\ttotal: 1m 57s\tremaining: 2m 35s\n",
      "172:\tlearn: 0.9300000\ttest: 0.8033333\tbest: 0.8066667 (170)\ttotal: 1m 58s\tremaining: 2m 34s\n",
      "173:\tlearn: 0.9314286\ttest: 0.8050000\tbest: 0.8066667 (170)\ttotal: 1m 58s\tremaining: 2m 34s\n",
      "174:\tlearn: 0.9328571\ttest: 0.8016667\tbest: 0.8066667 (170)\ttotal: 1m 59s\tremaining: 2m 33s\n",
      "175:\tlearn: 0.9342857\ttest: 0.8016667\tbest: 0.8066667 (170)\ttotal: 2m\tremaining: 2m 32s\n",
      "176:\tlearn: 0.9342857\ttest: 0.8016667\tbest: 0.8066667 (170)\ttotal: 2m\tremaining: 2m 32s\n",
      "177:\tlearn: 0.9342857\ttest: 0.8016667\tbest: 0.8066667 (170)\ttotal: 2m 1s\tremaining: 2m 31s\n",
      "178:\tlearn: 0.9342857\ttest: 0.7966667\tbest: 0.8066667 (170)\ttotal: 2m 2s\tremaining: 2m 30s\n",
      "179:\tlearn: 0.9364286\ttest: 0.8016667\tbest: 0.8066667 (170)\ttotal: 2m 2s\tremaining: 2m 30s\n",
      "180:\tlearn: 0.9378571\ttest: 0.8050000\tbest: 0.8066667 (170)\ttotal: 2m 3s\tremaining: 2m 29s\n",
      "181:\tlearn: 0.9350000\ttest: 0.8033333\tbest: 0.8066667 (170)\ttotal: 2m 4s\tremaining: 2m 28s\n",
      "182:\tlearn: 0.9364286\ttest: 0.8066667\tbest: 0.8066667 (170)\ttotal: 2m 4s\tremaining: 2m 28s\n",
      "183:\tlearn: 0.9364286\ttest: 0.8050000\tbest: 0.8066667 (170)\ttotal: 2m 5s\tremaining: 2m 27s\n",
      "184:\tlearn: 0.9364286\ttest: 0.8066667\tbest: 0.8066667 (170)\ttotal: 2m 6s\tremaining: 2m 26s\n",
      "185:\tlearn: 0.9364286\ttest: 0.8066667\tbest: 0.8066667 (170)\ttotal: 2m 7s\tremaining: 2m 26s\n",
      "186:\tlearn: 0.9371429\ttest: 0.8066667\tbest: 0.8066667 (170)\ttotal: 2m 7s\tremaining: 2m 25s\n",
      "187:\tlearn: 0.9364286\ttest: 0.8100000\tbest: 0.8100000 (187)\ttotal: 2m 8s\tremaining: 2m 24s\n",
      "188:\tlearn: 0.9357143\ttest: 0.8083333\tbest: 0.8100000 (187)\ttotal: 2m 9s\tremaining: 2m 24s\n",
      "189:\tlearn: 0.9364286\ttest: 0.8100000\tbest: 0.8100000 (187)\ttotal: 2m 9s\tremaining: 2m 23s\n",
      "190:\tlearn: 0.9385714\ttest: 0.8100000\tbest: 0.8100000 (187)\ttotal: 2m 10s\tremaining: 2m 22s\n",
      "191:\tlearn: 0.9385714\ttest: 0.8100000\tbest: 0.8100000 (187)\ttotal: 2m 11s\tremaining: 2m 21s\n",
      "192:\tlearn: 0.9392857\ttest: 0.8100000\tbest: 0.8100000 (187)\ttotal: 2m 11s\tremaining: 2m 21s\n",
      "193:\tlearn: 0.9371429\ttest: 0.8100000\tbest: 0.8100000 (187)\ttotal: 2m 12s\tremaining: 2m 20s\n",
      "194:\tlearn: 0.9378571\ttest: 0.8100000\tbest: 0.8100000 (187)\ttotal: 2m 13s\tremaining: 2m 19s\n",
      "195:\tlearn: 0.9400000\ttest: 0.8083333\tbest: 0.8100000 (187)\ttotal: 2m 13s\tremaining: 2m 19s\n",
      "196:\tlearn: 0.9407143\ttest: 0.8066667\tbest: 0.8100000 (187)\ttotal: 2m 14s\tremaining: 2m 18s\n",
      "197:\tlearn: 0.9435714\ttest: 0.8066667\tbest: 0.8100000 (187)\ttotal: 2m 15s\tremaining: 2m 17s\n",
      "198:\tlearn: 0.9442857\ttest: 0.8083333\tbest: 0.8100000 (187)\ttotal: 2m 15s\tremaining: 2m 17s\n",
      "199:\tlearn: 0.9450000\ttest: 0.8083333\tbest: 0.8100000 (187)\ttotal: 2m 16s\tremaining: 2m 16s\n",
      "200:\tlearn: 0.9457143\ttest: 0.8116667\tbest: 0.8116667 (200)\ttotal: 2m 17s\tremaining: 2m 15s\n",
      "201:\tlearn: 0.9464286\ttest: 0.8100000\tbest: 0.8116667 (200)\ttotal: 2m 17s\tremaining: 2m 15s\n",
      "202:\tlearn: 0.9464286\ttest: 0.8066667\tbest: 0.8116667 (200)\ttotal: 2m 18s\tremaining: 2m 14s\n",
      "203:\tlearn: 0.9471429\ttest: 0.8066667\tbest: 0.8116667 (200)\ttotal: 2m 19s\tremaining: 2m 13s\n",
      "204:\tlearn: 0.9471429\ttest: 0.8066667\tbest: 0.8116667 (200)\ttotal: 2m 20s\tremaining: 2m 13s\n",
      "205:\tlearn: 0.9478571\ttest: 0.8033333\tbest: 0.8116667 (200)\ttotal: 2m 20s\tremaining: 2m 12s\n",
      "206:\tlearn: 0.9492857\ttest: 0.8066667\tbest: 0.8116667 (200)\ttotal: 2m 21s\tremaining: 2m 11s\n",
      "207:\tlearn: 0.9492857\ttest: 0.8066667\tbest: 0.8116667 (200)\ttotal: 2m 22s\tremaining: 2m 11s\n",
      "208:\tlearn: 0.9492857\ttest: 0.8083333\tbest: 0.8116667 (200)\ttotal: 2m 22s\tremaining: 2m 10s\n",
      "209:\tlearn: 0.9492857\ttest: 0.8050000\tbest: 0.8116667 (200)\ttotal: 2m 23s\tremaining: 2m 9s\n",
      "210:\tlearn: 0.9492857\ttest: 0.8066667\tbest: 0.8116667 (200)\ttotal: 2m 24s\tremaining: 2m 9s\n",
      "211:\tlearn: 0.9500000\ttest: 0.8083333\tbest: 0.8116667 (200)\ttotal: 2m 24s\tremaining: 2m 8s\n",
      "212:\tlearn: 0.9507143\ttest: 0.8083333\tbest: 0.8116667 (200)\ttotal: 2m 25s\tremaining: 2m 7s\n",
      "213:\tlearn: 0.9528571\ttest: 0.8083333\tbest: 0.8116667 (200)\ttotal: 2m 26s\tremaining: 2m 7s\n",
      "214:\tlearn: 0.9535714\ttest: 0.8066667\tbest: 0.8116667 (200)\ttotal: 2m 26s\tremaining: 2m 6s\n",
      "215:\tlearn: 0.9535714\ttest: 0.8066667\tbest: 0.8116667 (200)\ttotal: 2m 27s\tremaining: 2m 5s\n",
      "216:\tlearn: 0.9535714\ttest: 0.8050000\tbest: 0.8116667 (200)\ttotal: 2m 28s\tremaining: 2m 5s\n",
      "217:\tlearn: 0.9542857\ttest: 0.8083333\tbest: 0.8116667 (200)\ttotal: 2m 29s\tremaining: 2m 4s\n",
      "218:\tlearn: 0.9542857\ttest: 0.8050000\tbest: 0.8116667 (200)\ttotal: 2m 29s\tremaining: 2m 3s\n",
      "219:\tlearn: 0.9542857\ttest: 0.8016667\tbest: 0.8116667 (200)\ttotal: 2m 30s\tremaining: 2m 3s\n",
      "220:\tlearn: 0.9542857\ttest: 0.8066667\tbest: 0.8116667 (200)\ttotal: 2m 31s\tremaining: 2m 2s\n",
      "221:\tlearn: 0.9535714\ttest: 0.8050000\tbest: 0.8116667 (200)\ttotal: 2m 31s\tremaining: 2m 1s\n",
      "222:\tlearn: 0.9557143\ttest: 0.8033333\tbest: 0.8116667 (200)\ttotal: 2m 32s\tremaining: 2m 1s\n",
      "223:\tlearn: 0.9564286\ttest: 0.8033333\tbest: 0.8116667 (200)\ttotal: 2m 33s\tremaining: 2m\n",
      "224:\tlearn: 0.9564286\ttest: 0.8083333\tbest: 0.8116667 (200)\ttotal: 2m 33s\tremaining: 1m 59s\n",
      "225:\tlearn: 0.9571429\ttest: 0.8066667\tbest: 0.8116667 (200)\ttotal: 2m 34s\tremaining: 1m 58s\n",
      "226:\tlearn: 0.9557143\ttest: 0.8100000\tbest: 0.8116667 (200)\ttotal: 2m 35s\tremaining: 1m 58s\n",
      "227:\tlearn: 0.9557143\ttest: 0.8066667\tbest: 0.8116667 (200)\ttotal: 2m 35s\tremaining: 1m 57s\n",
      "228:\tlearn: 0.9557143\ttest: 0.8066667\tbest: 0.8116667 (200)\ttotal: 2m 36s\tremaining: 1m 56s\n",
      "229:\tlearn: 0.9564286\ttest: 0.8066667\tbest: 0.8116667 (200)\ttotal: 2m 37s\tremaining: 1m 56s\n",
      "230:\tlearn: 0.9564286\ttest: 0.8066667\tbest: 0.8116667 (200)\ttotal: 2m 37s\tremaining: 1m 55s\n",
      "231:\tlearn: 0.9578571\ttest: 0.8066667\tbest: 0.8116667 (200)\ttotal: 2m 38s\tremaining: 1m 54s\n",
      "232:\tlearn: 0.9592857\ttest: 0.8033333\tbest: 0.8116667 (200)\ttotal: 2m 39s\tremaining: 1m 54s\n",
      "233:\tlearn: 0.9592857\ttest: 0.8033333\tbest: 0.8116667 (200)\ttotal: 2m 40s\tremaining: 1m 53s\n",
      "234:\tlearn: 0.9600000\ttest: 0.8033333\tbest: 0.8116667 (200)\ttotal: 2m 40s\tremaining: 1m 52s\n",
      "235:\tlearn: 0.9600000\ttest: 0.8033333\tbest: 0.8116667 (200)\ttotal: 2m 41s\tremaining: 1m 52s\n",
      "236:\tlearn: 0.9592857\ttest: 0.8050000\tbest: 0.8116667 (200)\ttotal: 2m 42s\tremaining: 1m 51s\n",
      "237:\tlearn: 0.9592857\ttest: 0.8033333\tbest: 0.8116667 (200)\ttotal: 2m 42s\tremaining: 1m 50s\n",
      "238:\tlearn: 0.9607143\ttest: 0.8050000\tbest: 0.8116667 (200)\ttotal: 2m 43s\tremaining: 1m 50s\n",
      "239:\tlearn: 0.9621429\ttest: 0.8083333\tbest: 0.8116667 (200)\ttotal: 2m 44s\tremaining: 1m 49s\n",
      "240:\tlearn: 0.9621429\ttest: 0.8083333\tbest: 0.8116667 (200)\ttotal: 2m 44s\tremaining: 1m 48s\n",
      "241:\tlearn: 0.9621429\ttest: 0.8083333\tbest: 0.8116667 (200)\ttotal: 2m 45s\tremaining: 1m 48s\n",
      "242:\tlearn: 0.9621429\ttest: 0.8083333\tbest: 0.8116667 (200)\ttotal: 2m 46s\tremaining: 1m 47s\n",
      "243:\tlearn: 0.9628571\ttest: 0.8083333\tbest: 0.8116667 (200)\ttotal: 2m 46s\tremaining: 1m 46s\n",
      "244:\tlearn: 0.9642857\ttest: 0.8050000\tbest: 0.8116667 (200)\ttotal: 2m 47s\tremaining: 1m 46s\n",
      "245:\tlearn: 0.9650000\ttest: 0.8050000\tbest: 0.8116667 (200)\ttotal: 2m 48s\tremaining: 1m 45s\n",
      "246:\tlearn: 0.9657143\ttest: 0.8066667\tbest: 0.8116667 (200)\ttotal: 2m 49s\tremaining: 1m 44s\n",
      "247:\tlearn: 0.9657143\ttest: 0.8083333\tbest: 0.8116667 (200)\ttotal: 2m 49s\tremaining: 1m 43s\n",
      "248:\tlearn: 0.9664286\ttest: 0.8066667\tbest: 0.8116667 (200)\ttotal: 2m 50s\tremaining: 1m 43s\n",
      "249:\tlearn: 0.9671429\ttest: 0.8083333\tbest: 0.8116667 (200)\ttotal: 2m 51s\tremaining: 1m 42s\n",
      "250:\tlearn: 0.9671429\ttest: 0.8083333\tbest: 0.8116667 (200)\ttotal: 2m 51s\tremaining: 1m 41s\n",
      "251:\tlearn: 0.9678571\ttest: 0.8083333\tbest: 0.8116667 (200)\ttotal: 2m 52s\tremaining: 1m 41s\n",
      "252:\tlearn: 0.9678571\ttest: 0.8083333\tbest: 0.8116667 (200)\ttotal: 2m 53s\tremaining: 1m 40s\n",
      "253:\tlearn: 0.9692857\ttest: 0.8100000\tbest: 0.8116667 (200)\ttotal: 2m 53s\tremaining: 1m 39s\n",
      "254:\tlearn: 0.9700000\ttest: 0.8083333\tbest: 0.8116667 (200)\ttotal: 2m 54s\tremaining: 1m 39s\n",
      "255:\tlearn: 0.9692857\ttest: 0.8100000\tbest: 0.8116667 (200)\ttotal: 2m 55s\tremaining: 1m 38s\n",
      "256:\tlearn: 0.9714286\ttest: 0.8116667\tbest: 0.8116667 (200)\ttotal: 2m 55s\tremaining: 1m 37s\n",
      "257:\tlearn: 0.9721429\ttest: 0.8083333\tbest: 0.8116667 (200)\ttotal: 2m 56s\tremaining: 1m 37s\n",
      "258:\tlearn: 0.9721429\ttest: 0.8116667\tbest: 0.8116667 (200)\ttotal: 2m 57s\tremaining: 1m 36s\n",
      "259:\tlearn: 0.9714286\ttest: 0.8116667\tbest: 0.8116667 (200)\ttotal: 2m 58s\tremaining: 1m 35s\n",
      "260:\tlearn: 0.9707143\ttest: 0.8133333\tbest: 0.8133333 (260)\ttotal: 2m 58s\tremaining: 1m 35s\n",
      "261:\tlearn: 0.9721429\ttest: 0.8116667\tbest: 0.8133333 (260)\ttotal: 2m 59s\tremaining: 1m 34s\n",
      "262:\tlearn: 0.9721429\ttest: 0.8083333\tbest: 0.8133333 (260)\ttotal: 3m\tremaining: 1m 33s\n",
      "263:\tlearn: 0.9728571\ttest: 0.8116667\tbest: 0.8133333 (260)\ttotal: 3m\tremaining: 1m 33s\n",
      "264:\tlearn: 0.9721429\ttest: 0.8066667\tbest: 0.8133333 (260)\ttotal: 3m 1s\tremaining: 1m 32s\n",
      "265:\tlearn: 0.9721429\ttest: 0.8100000\tbest: 0.8133333 (260)\ttotal: 3m 2s\tremaining: 1m 31s\n",
      "266:\tlearn: 0.9721429\ttest: 0.8100000\tbest: 0.8133333 (260)\ttotal: 3m 2s\tremaining: 1m 31s\n",
      "267:\tlearn: 0.9735714\ttest: 0.8083333\tbest: 0.8133333 (260)\ttotal: 3m 3s\tremaining: 1m 30s\n",
      "268:\tlearn: 0.9735714\ttest: 0.8100000\tbest: 0.8133333 (260)\ttotal: 3m 4s\tremaining: 1m 29s\n",
      "269:\tlearn: 0.9742857\ttest: 0.8066667\tbest: 0.8133333 (260)\ttotal: 3m 4s\tremaining: 1m 29s\n",
      "270:\tlearn: 0.9735714\ttest: 0.8083333\tbest: 0.8133333 (260)\ttotal: 3m 5s\tremaining: 1m 28s\n",
      "271:\tlearn: 0.9742857\ttest: 0.8083333\tbest: 0.8133333 (260)\ttotal: 3m 6s\tremaining: 1m 27s\n",
      "272:\tlearn: 0.9750000\ttest: 0.8066667\tbest: 0.8133333 (260)\ttotal: 3m 6s\tremaining: 1m 26s\n",
      "273:\tlearn: 0.9757143\ttest: 0.8066667\tbest: 0.8133333 (260)\ttotal: 3m 7s\tremaining: 1m 26s\n",
      "274:\tlearn: 0.9764286\ttest: 0.8083333\tbest: 0.8133333 (260)\ttotal: 3m 8s\tremaining: 1m 25s\n",
      "275:\tlearn: 0.9771429\ttest: 0.8100000\tbest: 0.8133333 (260)\ttotal: 3m 9s\tremaining: 1m 24s\n",
      "276:\tlearn: 0.9778571\ttest: 0.8083333\tbest: 0.8133333 (260)\ttotal: 3m 9s\tremaining: 1m 24s\n",
      "277:\tlearn: 0.9778571\ttest: 0.8066667\tbest: 0.8133333 (260)\ttotal: 3m 10s\tremaining: 1m 23s\n",
      "278:\tlearn: 0.9778571\ttest: 0.8083333\tbest: 0.8133333 (260)\ttotal: 3m 11s\tremaining: 1m 22s\n",
      "279:\tlearn: 0.9785714\ttest: 0.8083333\tbest: 0.8133333 (260)\ttotal: 3m 11s\tremaining: 1m 22s\n",
      "280:\tlearn: 0.9792857\ttest: 0.8083333\tbest: 0.8133333 (260)\ttotal: 3m 12s\tremaining: 1m 21s\n",
      "281:\tlearn: 0.9800000\ttest: 0.8066667\tbest: 0.8133333 (260)\ttotal: 3m 13s\tremaining: 1m 20s\n",
      "282:\tlearn: 0.9814286\ttest: 0.8083333\tbest: 0.8133333 (260)\ttotal: 3m 13s\tremaining: 1m 20s\n",
      "283:\tlearn: 0.9814286\ttest: 0.8083333\tbest: 0.8133333 (260)\ttotal: 3m 14s\tremaining: 1m 19s\n",
      "284:\tlearn: 0.9821429\ttest: 0.8083333\tbest: 0.8133333 (260)\ttotal: 3m 15s\tremaining: 1m 18s\n",
      "285:\tlearn: 0.9835714\ttest: 0.8100000\tbest: 0.8133333 (260)\ttotal: 3m 15s\tremaining: 1m 18s\n",
      "286:\tlearn: 0.9835714\ttest: 0.8116667\tbest: 0.8133333 (260)\ttotal: 3m 16s\tremaining: 1m 17s\n",
      "287:\tlearn: 0.9828571\ttest: 0.8150000\tbest: 0.8150000 (287)\ttotal: 3m 17s\tremaining: 1m 16s\n",
      "288:\tlearn: 0.9835714\ttest: 0.8100000\tbest: 0.8150000 (287)\ttotal: 3m 18s\tremaining: 1m 16s\n",
      "289:\tlearn: 0.9835714\ttest: 0.8116667\tbest: 0.8150000 (287)\ttotal: 3m 18s\tremaining: 1m 15s\n",
      "290:\tlearn: 0.9850000\ttest: 0.8116667\tbest: 0.8150000 (287)\ttotal: 3m 19s\tremaining: 1m 14s\n",
      "291:\tlearn: 0.9857143\ttest: 0.8116667\tbest: 0.8150000 (287)\ttotal: 3m 20s\tremaining: 1m 14s\n",
      "292:\tlearn: 0.9864286\ttest: 0.8116667\tbest: 0.8150000 (287)\ttotal: 3m 20s\tremaining: 1m 13s\n",
      "293:\tlearn: 0.9878571\ttest: 0.8100000\tbest: 0.8150000 (287)\ttotal: 3m 21s\tremaining: 1m 12s\n",
      "294:\tlearn: 0.9892857\ttest: 0.8083333\tbest: 0.8150000 (287)\ttotal: 3m 22s\tremaining: 1m 11s\n",
      "295:\tlearn: 0.9892857\ttest: 0.8083333\tbest: 0.8150000 (287)\ttotal: 3m 22s\tremaining: 1m 11s\n",
      "296:\tlearn: 0.9892857\ttest: 0.8066667\tbest: 0.8150000 (287)\ttotal: 3m 23s\tremaining: 1m 10s\n",
      "297:\tlearn: 0.9900000\ttest: 0.8083333\tbest: 0.8150000 (287)\ttotal: 3m 24s\tremaining: 1m 9s\n",
      "298:\tlearn: 0.9900000\ttest: 0.8133333\tbest: 0.8150000 (287)\ttotal: 3m 24s\tremaining: 1m 9s\n",
      "299:\tlearn: 0.9900000\ttest: 0.8133333\tbest: 0.8150000 (287)\ttotal: 3m 25s\tremaining: 1m 8s\n",
      "300:\tlearn: 0.9900000\ttest: 0.8116667\tbest: 0.8150000 (287)\ttotal: 3m 26s\tremaining: 1m 7s\n",
      "301:\tlearn: 0.9914286\ttest: 0.8116667\tbest: 0.8150000 (287)\ttotal: 3m 26s\tremaining: 1m 7s\n",
      "302:\tlearn: 0.9907143\ttest: 0.8100000\tbest: 0.8150000 (287)\ttotal: 3m 27s\tremaining: 1m 6s\n",
      "303:\tlearn: 0.9914286\ttest: 0.8116667\tbest: 0.8150000 (287)\ttotal: 3m 28s\tremaining: 1m 5s\n",
      "304:\tlearn: 0.9935714\ttest: 0.8116667\tbest: 0.8150000 (287)\ttotal: 3m 29s\tremaining: 1m 5s\n",
      "305:\tlearn: 0.9928571\ttest: 0.8150000\tbest: 0.8150000 (287)\ttotal: 3m 29s\tremaining: 1m 4s\n",
      "306:\tlearn: 0.9935714\ttest: 0.8116667\tbest: 0.8150000 (287)\ttotal: 3m 30s\tremaining: 1m 3s\n",
      "307:\tlearn: 0.9935714\ttest: 0.8116667\tbest: 0.8150000 (287)\ttotal: 3m 31s\tremaining: 1m 3s\n",
      "308:\tlearn: 0.9935714\ttest: 0.8116667\tbest: 0.8150000 (287)\ttotal: 3m 31s\tremaining: 1m 2s\n",
      "309:\tlearn: 0.9942857\ttest: 0.8116667\tbest: 0.8150000 (287)\ttotal: 3m 32s\tremaining: 1m 1s\n",
      "310:\tlearn: 0.9935714\ttest: 0.8100000\tbest: 0.8150000 (287)\ttotal: 3m 33s\tremaining: 1m 1s\n",
      "311:\tlearn: 0.9935714\ttest: 0.8116667\tbest: 0.8150000 (287)\ttotal: 3m 33s\tremaining: 1m\n",
      "312:\tlearn: 0.9942857\ttest: 0.8083333\tbest: 0.8150000 (287)\ttotal: 3m 34s\tremaining: 59.7s\n",
      "313:\tlearn: 0.9942857\ttest: 0.8100000\tbest: 0.8150000 (287)\ttotal: 3m 35s\tremaining: 59s\n",
      "314:\tlearn: 0.9950000\ttest: 0.8066667\tbest: 0.8150000 (287)\ttotal: 3m 35s\tremaining: 58.3s\n",
      "315:\tlearn: 0.9950000\ttest: 0.8116667\tbest: 0.8150000 (287)\ttotal: 3m 36s\tremaining: 57.6s\n",
      "316:\tlearn: 0.9950000\ttest: 0.8083333\tbest: 0.8150000 (287)\ttotal: 3m 37s\tremaining: 56.9s\n",
      "317:\tlearn: 0.9950000\ttest: 0.8050000\tbest: 0.8150000 (287)\ttotal: 3m 37s\tremaining: 56.2s\n",
      "318:\tlearn: 0.9950000\ttest: 0.8033333\tbest: 0.8150000 (287)\ttotal: 3m 38s\tremaining: 55.5s\n",
      "319:\tlearn: 0.9957143\ttest: 0.8016667\tbest: 0.8150000 (287)\ttotal: 3m 39s\tremaining: 54.8s\n",
      "320:\tlearn: 0.9957143\ttest: 0.8050000\tbest: 0.8150000 (287)\ttotal: 3m 40s\tremaining: 54.2s\n",
      "321:\tlearn: 0.9957143\ttest: 0.8066667\tbest: 0.8150000 (287)\ttotal: 3m 40s\tremaining: 53.5s\n",
      "322:\tlearn: 0.9957143\ttest: 0.8100000\tbest: 0.8150000 (287)\ttotal: 3m 41s\tremaining: 52.8s\n",
      "323:\tlearn: 0.9971429\ttest: 0.8066667\tbest: 0.8150000 (287)\ttotal: 3m 42s\tremaining: 52.1s\n",
      "324:\tlearn: 0.9971429\ttest: 0.8066667\tbest: 0.8150000 (287)\ttotal: 3m 42s\tremaining: 51.4s\n",
      "325:\tlearn: 0.9971429\ttest: 0.8066667\tbest: 0.8150000 (287)\ttotal: 3m 43s\tremaining: 50.7s\n",
      "326:\tlearn: 0.9971429\ttest: 0.8066667\tbest: 0.8150000 (287)\ttotal: 3m 44s\tremaining: 50.1s\n",
      "327:\tlearn: 0.9971429\ttest: 0.8100000\tbest: 0.8150000 (287)\ttotal: 3m 44s\tremaining: 49.4s\n",
      "328:\tlearn: 0.9971429\ttest: 0.8100000\tbest: 0.8150000 (287)\ttotal: 3m 45s\tremaining: 48.7s\n",
      "329:\tlearn: 0.9971429\ttest: 0.8083333\tbest: 0.8150000 (287)\ttotal: 3m 46s\tremaining: 48s\n",
      "330:\tlearn: 0.9971429\ttest: 0.8033333\tbest: 0.8150000 (287)\ttotal: 3m 47s\tremaining: 47.3s\n",
      "331:\tlearn: 0.9971429\ttest: 0.8016667\tbest: 0.8150000 (287)\ttotal: 3m 47s\tremaining: 46.6s\n",
      "332:\tlearn: 0.9971429\ttest: 0.8050000\tbest: 0.8150000 (287)\ttotal: 3m 48s\tremaining: 46s\n",
      "333:\tlearn: 0.9971429\ttest: 0.8033333\tbest: 0.8150000 (287)\ttotal: 3m 49s\tremaining: 45.3s\n",
      "334:\tlearn: 0.9978571\ttest: 0.8050000\tbest: 0.8150000 (287)\ttotal: 3m 49s\tremaining: 44.6s\n",
      "335:\tlearn: 0.9978571\ttest: 0.8033333\tbest: 0.8150000 (287)\ttotal: 3m 50s\tremaining: 43.9s\n",
      "336:\tlearn: 0.9978571\ttest: 0.8000000\tbest: 0.8150000 (287)\ttotal: 3m 51s\tremaining: 43.2s\n",
      "337:\tlearn: 0.9978571\ttest: 0.8050000\tbest: 0.8150000 (287)\ttotal: 3m 51s\tremaining: 42.5s\n",
      "338:\tlearn: 0.9978571\ttest: 0.8066667\tbest: 0.8150000 (287)\ttotal: 3m 52s\tremaining: 41.9s\n",
      "339:\tlearn: 0.9978571\ttest: 0.8066667\tbest: 0.8150000 (287)\ttotal: 3m 53s\tremaining: 41.2s\n",
      "340:\tlearn: 0.9978571\ttest: 0.8100000\tbest: 0.8150000 (287)\ttotal: 3m 53s\tremaining: 40.5s\n",
      "341:\tlearn: 0.9978571\ttest: 0.8066667\tbest: 0.8150000 (287)\ttotal: 3m 54s\tremaining: 39.8s\n",
      "342:\tlearn: 0.9978571\ttest: 0.8066667\tbest: 0.8150000 (287)\ttotal: 3m 55s\tremaining: 39.1s\n",
      "343:\tlearn: 0.9978571\ttest: 0.8083333\tbest: 0.8150000 (287)\ttotal: 3m 55s\tremaining: 38.4s\n",
      "344:\tlearn: 0.9978571\ttest: 0.8116667\tbest: 0.8150000 (287)\ttotal: 3m 56s\tremaining: 37.7s\n",
      "345:\tlearn: 0.9978571\ttest: 0.8133333\tbest: 0.8150000 (287)\ttotal: 3m 57s\tremaining: 37s\n",
      "346:\tlearn: 0.9978571\ttest: 0.8150000\tbest: 0.8150000 (287)\ttotal: 3m 58s\tremaining: 36.4s\n",
      "347:\tlearn: 0.9978571\ttest: 0.8150000\tbest: 0.8150000 (287)\ttotal: 3m 58s\tremaining: 35.7s\n",
      "348:\tlearn: 0.9978571\ttest: 0.8100000\tbest: 0.8150000 (287)\ttotal: 3m 59s\tremaining: 35s\n",
      "349:\tlearn: 0.9978571\ttest: 0.8100000\tbest: 0.8150000 (287)\ttotal: 4m\tremaining: 34.3s\n",
      "350:\tlearn: 0.9978571\ttest: 0.8133333\tbest: 0.8150000 (287)\ttotal: 4m\tremaining: 33.6s\n",
      "351:\tlearn: 0.9978571\ttest: 0.8133333\tbest: 0.8150000 (287)\ttotal: 4m 1s\tremaining: 32.9s\n",
      "352:\tlearn: 0.9978571\ttest: 0.8116667\tbest: 0.8150000 (287)\ttotal: 4m 2s\tremaining: 32.3s\n",
      "353:\tlearn: 0.9978571\ttest: 0.8100000\tbest: 0.8150000 (287)\ttotal: 4m 2s\tremaining: 31.6s\n",
      "354:\tlearn: 0.9978571\ttest: 0.8116667\tbest: 0.8150000 (287)\ttotal: 4m 3s\tremaining: 30.9s\n",
      "355:\tlearn: 0.9978571\ttest: 0.8133333\tbest: 0.8150000 (287)\ttotal: 4m 4s\tremaining: 30.2s\n",
      "356:\tlearn: 0.9985714\ttest: 0.8100000\tbest: 0.8150000 (287)\ttotal: 4m 4s\tremaining: 29.5s\n",
      "357:\tlearn: 0.9985714\ttest: 0.8083333\tbest: 0.8150000 (287)\ttotal: 4m 5s\tremaining: 28.8s\n",
      "358:\tlearn: 0.9985714\ttest: 0.8100000\tbest: 0.8150000 (287)\ttotal: 4m 6s\tremaining: 28.1s\n",
      "359:\tlearn: 0.9985714\ttest: 0.8116667\tbest: 0.8150000 (287)\ttotal: 4m 7s\tremaining: 27.5s\n",
      "360:\tlearn: 0.9985714\ttest: 0.8133333\tbest: 0.8150000 (287)\ttotal: 4m 7s\tremaining: 26.8s\n",
      "361:\tlearn: 0.9985714\ttest: 0.8133333\tbest: 0.8150000 (287)\ttotal: 4m 8s\tremaining: 26.1s\n",
      "362:\tlearn: 0.9985714\ttest: 0.8150000\tbest: 0.8150000 (287)\ttotal: 4m 9s\tremaining: 25.4s\n",
      "363:\tlearn: 0.9985714\ttest: 0.8150000\tbest: 0.8150000 (287)\ttotal: 4m 9s\tremaining: 24.7s\n",
      "364:\tlearn: 0.9985714\ttest: 0.8116667\tbest: 0.8150000 (287)\ttotal: 4m 10s\tremaining: 24s\n",
      "365:\tlearn: 0.9985714\ttest: 0.8133333\tbest: 0.8150000 (287)\ttotal: 4m 11s\tremaining: 23.3s\n",
      "366:\tlearn: 0.9985714\ttest: 0.8133333\tbest: 0.8150000 (287)\ttotal: 4m 11s\tremaining: 22.7s\n",
      "367:\tlearn: 0.9985714\ttest: 0.8150000\tbest: 0.8150000 (287)\ttotal: 4m 12s\tremaining: 22s\n",
      "368:\tlearn: 0.9985714\ttest: 0.8133333\tbest: 0.8150000 (287)\ttotal: 4m 13s\tremaining: 21.3s\n",
      "369:\tlearn: 0.9985714\ttest: 0.8116667\tbest: 0.8150000 (287)\ttotal: 4m 13s\tremaining: 20.6s\n",
      "370:\tlearn: 0.9985714\ttest: 0.8116667\tbest: 0.8150000 (287)\ttotal: 4m 14s\tremaining: 19.9s\n",
      "371:\tlearn: 0.9985714\ttest: 0.8133333\tbest: 0.8150000 (287)\ttotal: 4m 15s\tremaining: 19.2s\n",
      "372:\tlearn: 0.9985714\ttest: 0.8150000\tbest: 0.8150000 (287)\ttotal: 4m 16s\tremaining: 18.5s\n",
      "373:\tlearn: 0.9985714\ttest: 0.8150000\tbest: 0.8150000 (287)\ttotal: 4m 16s\tremaining: 17.9s\n",
      "374:\tlearn: 0.9985714\ttest: 0.8083333\tbest: 0.8150000 (287)\ttotal: 4m 17s\tremaining: 17.2s\n",
      "375:\tlearn: 0.9985714\ttest: 0.8066667\tbest: 0.8150000 (287)\ttotal: 4m 18s\tremaining: 16.5s\n",
      "376:\tlearn: 0.9985714\ttest: 0.8083333\tbest: 0.8150000 (287)\ttotal: 4m 18s\tremaining: 15.8s\n",
      "377:\tlearn: 0.9985714\ttest: 0.8083333\tbest: 0.8150000 (287)\ttotal: 4m 19s\tremaining: 15.1s\n",
      "378:\tlearn: 0.9985714\ttest: 0.8083333\tbest: 0.8150000 (287)\ttotal: 4m 20s\tremaining: 14.4s\n",
      "379:\tlearn: 0.9985714\ttest: 0.8066667\tbest: 0.8150000 (287)\ttotal: 4m 20s\tremaining: 13.7s\n",
      "380:\tlearn: 0.9985714\ttest: 0.8066667\tbest: 0.8150000 (287)\ttotal: 4m 21s\tremaining: 13.1s\n",
      "381:\tlearn: 0.9985714\ttest: 0.8083333\tbest: 0.8150000 (287)\ttotal: 4m 22s\tremaining: 12.4s\n",
      "382:\tlearn: 0.9985714\ttest: 0.8083333\tbest: 0.8150000 (287)\ttotal: 4m 23s\tremaining: 11.7s\n",
      "383:\tlearn: 0.9985714\ttest: 0.8100000\tbest: 0.8150000 (287)\ttotal: 4m 23s\tremaining: 11s\n",
      "384:\tlearn: 0.9985714\ttest: 0.8100000\tbest: 0.8150000 (287)\ttotal: 4m 24s\tremaining: 10.3s\n",
      "385:\tlearn: 0.9985714\ttest: 0.8133333\tbest: 0.8150000 (287)\ttotal: 4m 25s\tremaining: 9.62s\n",
      "386:\tlearn: 0.9992857\ttest: 0.8150000\tbest: 0.8150000 (287)\ttotal: 4m 25s\tremaining: 8.93s\n",
      "387:\tlearn: 0.9992857\ttest: 0.8183333\tbest: 0.8183333 (387)\ttotal: 4m 26s\tremaining: 8.24s\n",
      "388:\tlearn: 0.9992857\ttest: 0.8166667\tbest: 0.8183333 (387)\ttotal: 4m 27s\tremaining: 7.56s\n",
      "389:\tlearn: 0.9992857\ttest: 0.8166667\tbest: 0.8183333 (387)\ttotal: 4m 27s\tremaining: 6.87s\n",
      "390:\tlearn: 0.9992857\ttest: 0.8150000\tbest: 0.8183333 (387)\ttotal: 4m 28s\tremaining: 6.18s\n",
      "391:\tlearn: 0.9992857\ttest: 0.8150000\tbest: 0.8183333 (387)\ttotal: 4m 29s\tremaining: 5.5s\n",
      "392:\tlearn: 0.9992857\ttest: 0.8150000\tbest: 0.8183333 (387)\ttotal: 4m 30s\tremaining: 4.81s\n",
      "393:\tlearn: 0.9992857\ttest: 0.8150000\tbest: 0.8183333 (387)\ttotal: 4m 30s\tremaining: 4.12s\n",
      "394:\tlearn: 1.0000000\ttest: 0.8183333\tbest: 0.8183333 (387)\ttotal: 4m 31s\tremaining: 3.44s\n",
      "395:\tlearn: 1.0000000\ttest: 0.8166667\tbest: 0.8183333 (387)\ttotal: 4m 32s\tremaining: 2.75s\n",
      "396:\tlearn: 1.0000000\ttest: 0.8183333\tbest: 0.8183333 (387)\ttotal: 4m 32s\tremaining: 2.06s\n",
      "397:\tlearn: 1.0000000\ttest: 0.8166667\tbest: 0.8183333 (387)\ttotal: 4m 33s\tremaining: 1.37s\n",
      "398:\tlearn: 1.0000000\ttest: 0.8166667\tbest: 0.8183333 (387)\ttotal: 4m 34s\tremaining: 687ms\n",
      "399:\tlearn: 1.0000000\ttest: 0.8200000\tbest: 0.8200000 (399)\ttotal: 4m 34s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.82\n",
      "bestIteration = 399\n",
      "\n",
      "CatBoost Train accuracy score: 1.0\n",
      "CatBoost Train classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       1.00      1.00      1.00       700\n",
      "         pos       1.00      1.00      1.00       700\n",
      "\n",
      "    accuracy                           1.00      1400\n",
      "   macro avg       1.00      1.00      1.00      1400\n",
      "weighted avg       1.00      1.00      1.00      1400\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "CatBoost Test accuracy score: 0.82\n",
      "CatBoost Test classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.80      0.85      0.83       300\n",
      "         pos       0.84      0.79      0.81       300\n",
      "\n",
      "    accuracy                           0.82       600\n",
      "   macro avg       0.82      0.82      0.82       600\n",
      "weighted avg       0.82      0.82      0.82       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CatBoostClassifier\n",
    "eval_dataset = Pool(X_test_text, y_test)\n",
    "cb = CatBoostClassifier(l2_leaf_reg = 0.9, depth = 7, iterations = 400, eval_metric='Accuracy')\n",
    "cb.fit(X_train_text, y_train, eval_set=eval_dataset)\n",
    "\n",
    "y_cb_train_pred = cb.predict(X_train_text)\n",
    "y_cb_test_pred = cb.predict(X_test_text)\n",
    "\n",
    "# evaluation of model\n",
    "print(f'CatBoost Train accuracy score: {accuracy_score(y_true = y_train, y_pred = y_cb_train_pred)}')\n",
    "print(f'CatBoost Train classification report:\\n {classification_report(y_true = y_train, y_pred = y_cb_train_pred)}')\n",
    "print('-' * 70)\n",
    "print(f'CatBoost Test accuracy score: {accuracy_score(y_true = y_test, y_pred = y_cb_test_pred)}')\n",
    "print(f'CatBoost Test classification report:\\n {classification_report(y_true = y_test, y_pred = y_cb_test_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18ef748-c600-47c1-8a54-bd9b6388df48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
